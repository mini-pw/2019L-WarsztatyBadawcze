{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for generating audit, model and task jsons\n",
    "\n",
    "### *Use only when the model works perfectly well as 'code.py' script*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize below functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_np_matrix_to_json(a):\n",
    "    output = {}\n",
    "    for i in range(len(a[0])):\n",
    "        output[str(a[0][i])] = int(a[1][i])\n",
    "    return output\n",
    "\n",
    "def summarize_categorical_variable(values, name, model):\n",
    "    model['preprocessing'][name] = {\n",
    "        \"name\": name,\n",
    "        \"type\": \"categorical\",\n",
    "        \"number_of_unique_values\": len(np.unique(values.dropna())),\n",
    "        \"number_of_missing_values\": int(values.isna().sum()),\n",
    "        \"cat_frequencies\": parse_np_matrix_to_json(np.unique(values.dropna(), return_counts=True)),\n",
    "        \"num_minimum\": None,\n",
    "        \"num_1qu\": None,\n",
    "        \"num_median\": None,\n",
    "        \"num_mean\": None,\n",
    "        \"num_3qu\": None,\n",
    "        \"num_maximum\": None\n",
    "    }\n",
    "    \n",
    "def summarize_numerical_variable(values, name, model):\n",
    "    model['preprocessing'][name] = {\n",
    "        \"name\": name,\n",
    "        \"type\": \"numerical\",\n",
    "        \"number_of_unique_values\": len(np.unique(values.dropna())),\n",
    "        \"number_of_missing_values\": int(values.isna().sum()),\n",
    "        \"cat_frequencies\": None,\n",
    "        \"num_minimum\": float(np.min(values.dropna())),\n",
    "        \"num_1qu\": float(np.percentile(values.dropna(),25)),\n",
    "        \"num_median\": float(np.percentile(values.dropna(),50)),\n",
    "        \"num_3q\": float(np.percentile(values.dropna(),75)),\n",
    "        \"num_maximum\": float(np.max(values.dropna()))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import pkg_resources\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_by = \"Siemashko\"\n",
    "date = datetime.datetime.now().strftime(\"%d-%m-%Y\")\n",
    "dataset_id = \"openml_kc1-numeric\"\n",
    "task_type = \"regression\"\n",
    "task_target = \"NUMDEFECTS\"\n",
    "task_id = f'{task_type}_{task_target}'\n",
    "task = {\n",
    "    \"id\": task_id,\n",
    "    \"added_by\": added_by,\n",
    "    \"date\": date,\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"type\": task_type,\n",
    "    \"target\": task_target\n",
    "}\n",
    "\n",
    "with open('task.json', 'w') as fp:\n",
    "    json.dump([task], fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetOpenmlId = 1070\n",
    "\n",
    "dataset = openml.datasets.get_dataset(datasetOpenmlId)\n",
    "(X, y, categorical, names) = dataset.get_data(\n",
    "    target=dataset.default_target_attribute,\n",
    "    return_categorical_indicator=True,\n",
    "    return_attribute_names=True,\n",
    "    include_ignore_attributes=True\n",
    ")\n",
    "\n",
    "vals = {}\n",
    "for i, name in enumerate(names):\n",
    "    vals[name] = X[:, i]\n",
    "vals[dataset.default_target_attribute] = y\n",
    "df = pd.DataFrame(vals)\n",
    "\n",
    "X = df.drop('NUMDEFECTS', axis=1)\n",
    "y = df.loc[:, 'NUMDEFECTS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and md5 hash - remember to remain correct order of 'categorical' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "md5 = hashlib.md5(str(regressor).encode('utf-8')).hexdigest()\n",
    "\n",
    "model = {\n",
    "    \"id\": md5,\n",
    "    \"added_by\": added_by,\n",
    "    \"date\": date,\n",
    "    \"task_id\": task_id,\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"parameters\": classifier.get_params(),\n",
    "    \"preprocessing\": {}\n",
    "}\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if categorical[i]:\n",
    "        summarize_categorical_variable(X_train.loc[:,names[i]], names[i], model)\n",
    "    else:\n",
    "        summarize_numerical_variable(X_train.loc[:,names[i]], names[i], model)\n",
    "        \n",
    "\n",
    "with open('model.json', 'w') as fp:\n",
    "    json.dump([model], fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "audit = {\"id\": f'audit_{md5}',\n",
    "         \"added_by\": added_by,\n",
    "         \"date\": datetime.datetime.now().strftime(\"%d-%m-%Y\"),\n",
    "         \"model_id\": md5,\n",
    "         \"task_id\": task_id,\n",
    "         \"dataset_id\": dataset_id}\n",
    "\n",
    "audit['performance'] = {\n",
    "             \"MSE\": mean_squared_error(y_test, y_pred)\n",
    "         }\n",
    "\n",
    "with open('audit.json', 'w') as fp:\n",
    "    json.dump([audit], fp, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
