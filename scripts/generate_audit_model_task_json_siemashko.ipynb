{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for generating audit, model, task jsons, and code.py + sessionInfo.txt - basically everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Initialize below functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:24.036829Z",
     "start_time": "2019-04-02T22:21:24.009119Z"
    },
    "code_folding": [
     0,
     6,
     21
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parse_np_matrix_to_json(a):\n",
    "    output = {}\n",
    "    for i in range(len(a[0])):\n",
    "        output[str(a[0][i])] = int(a[1][i])\n",
    "    return output\n",
    "\n",
    "def summarize_categorical_variable(values, name, model):\n",
    "    model['preprocessing'][name] = {\n",
    "        \"name\": name,\n",
    "        \"type\": \"categorical\",\n",
    "        \"number_of_unique_values\": len(np.unique(values.dropna())),\n",
    "        \"number_of_missing_values\": int(values.isna().sum()),\n",
    "        \"cat_frequencies\": parse_np_matrix_to_json(np.unique(values.dropna(), return_counts=True)),\n",
    "        \"num_minimum\": None,\n",
    "        \"num_1qu\": None,\n",
    "        \"num_median\": None,\n",
    "        \"num_mean\": None,\n",
    "        \"num_3qu\": None,\n",
    "        \"num_maximum\": None\n",
    "    }\n",
    "    \n",
    "def summarize_numerical_variable(values, name, model):\n",
    "    model['preprocessing'][name] = {\n",
    "        \"name\": name,\n",
    "        \"type\": \"numerical\",\n",
    "        \"number_of_unique_values\": len(np.unique(values.dropna())),\n",
    "        \"number_of_missing_values\": int(values.isna().sum()),\n",
    "        \"cat_frequencies\": None,\n",
    "        \"num_minimum\": float(np.min(values.dropna())),\n",
    "        \"num_1qu\": float(np.percentile(values.dropna(),25)),\n",
    "        \"num_median\": float(np.percentile(values.dropna(),50)),\n",
    "        \"num_3qu\": float(np.percentile(values.dropna(),75)),\n",
    "        \"num_maximum\": float(np.max(values.dropna()))\n",
    "    }\n",
    "    \n",
    "def generate_task_json(dataset_id, task_type, task_target, added_by):\n",
    "    global task_id, date\n",
    "    date = datetime.datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    task_id = f'{task_type}_{task_target}'\n",
    "    task = {\n",
    "        \"id\": task_id,\n",
    "        \"added_by\": added_by,\n",
    "        \"date\": date,\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"type\": task_type,\n",
    "        \"target\": task_target\n",
    "    }\n",
    "\n",
    "    with open('task.json', 'w') as fp:\n",
    "        json.dump([task], fp, indent=4)\n",
    "        \n",
    "def load_data(dataset_openml_id, task_traget):\n",
    "    global names\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    dataset = openml.datasets.get_dataset(dataset_openml_id)\n",
    "    (X, y, categorical, names) = dataset.get_data(\n",
    "        target=dataset.default_target_attribute,\n",
    "        return_categorical_indicator=True,\n",
    "        return_attribute_names=True,\n",
    "        include_ignore_attributes=True\n",
    "    )\n",
    "\n",
    "    vals = {}\n",
    "    for i, name in enumerate(names):\n",
    "        vals[name] = X[:, i]\n",
    "    vals[dataset.default_target_attribute] = y\n",
    "    df = pd.DataFrame(vals)\n",
    "    X = df.drop(task_target, axis=1)\n",
    "    y = df.loc[:, task_target]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def generate_model_audit_json_and_code_py_for_classifier(classifier_class, params, repository_absolute_path):\n",
    "    classifier = classifier_class(**params)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    md5 = hashlib.md5(str(classifier).encode('utf-8')).hexdigest()\n",
    "\n",
    "    model = {\n",
    "        \"id\": md5,\n",
    "        \"added_by\": added_by,\n",
    "        \"date\": date,\n",
    "        \"library\": \"scikit\",\n",
    "        \"model_name\": classifier_class.__name__,\n",
    "        \"task_id\": task_id,\n",
    "        \"dataset_id\": dataset_id,\n",
    "        \"parameters\": classifier.get_params(),\n",
    "        \"preprocessing\": {}\n",
    "    }\n",
    "\n",
    "    print(f'md5 hash: {md5}')\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        if categorical[i]:\n",
    "            summarize_categorical_variable(X_train.loc[:,names[i]], names[i], model)\n",
    "        else:\n",
    "            summarize_numerical_variable(X_train.loc[:,names[i]], names[i], model)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'{repository_absolute_path}/models/{dataset_id}/{task_id}/{md5}')\n",
    "    except:\n",
    "        print(f'Directory {md5} already exists')\n",
    "\n",
    "    with open(f'{repository_absolute_path}/models/{dataset_id}/{task_id}/{md5}/model.json', 'w') as fp:\n",
    "        json.dump([model], fp, indent=4)\n",
    "\n",
    "    y_pred = classifier.predict(transform_pipeline.transform(X_test))\n",
    "    y_pred_proba = classifier.predict_proba(transform_pipeline.transform(X_test))[:,1]\n",
    "\n",
    "    audit = {\"id\": f'audit_{md5}',\n",
    "             \"date\": datetime.datetime.now().strftime(\"%d-%m-%Y\"),\n",
    "             \"added_by\": added_by,\n",
    "             \"model_id\": md5,\n",
    "             \"task_id\": task_id,\n",
    "             \"dataset_id\": dataset_id}\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    audit['performance'] = {\n",
    "                 \"acc\": accuracy_score(y_test, y_pred),\n",
    "                 \"auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "                 \"precision\": precision_score(y_test, y_pred),\n",
    "                 \"recall\": recall_score(y_test, y_pred),\n",
    "                 \"specificity\": tn/(tn+fp),\n",
    "                 \"f1\": f1_score(y_test, y_pred)\n",
    "             }\n",
    "\n",
    "    with open(f'{repository_absolute_path}/models/{dataset_id}/{task_id}/{md5}/audit.json', 'w') as fp:\n",
    "        json.dump([audit], fp, indent=4)\n",
    "        \n",
    "    sessionInfo = {\n",
    "        \"python_version\": python_version(),\n",
    "        \"library_versions\":[str(d) for d in pkg_resources.working_set]\n",
    "    }\n",
    "    with open(f'{repository_absolute_path}/models/{dataset_id}/{task_id}/{md5}/sessionInfo.txt', 'w') as f:\n",
    "        json.dump(sessionInfo, f, indent=4)\n",
    "    \n",
    "    code_py = f\"\"\"\n",
    "#:# libraries\n",
    "from {classifier_class.__module__} import {classifier_class.__name__}\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import pkg_resources\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "#:# config\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#:# data\n",
    "\n",
    "datasetId = {dataset_openml_id}\n",
    "task_target = '{task_target}'\n",
    "\n",
    "dataset = openml.datasets.get_dataset(datasetId)\n",
    "(X, y, categorical, names) = dataset.get_data(\n",
    "    target=dataset.default_target_attribute,\n",
    "    return_categorical_indicator=True,\n",
    "    return_attribute_names=True,\n",
    "    include_ignore_attributes=True\n",
    ")\n",
    "\n",
    "vals = {{}}\n",
    "for i, name in enumerate(names):\n",
    "    vals[name] = X[:, i]\n",
    "vals[dataset.default_target_attribute] = y\n",
    "df = pd.DataFrame(vals)\n",
    "\n",
    "X = df.drop(task_target, axis=1)\n",
    "y = df.loc[:, task_target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#:# preprocessing\n",
    "\n",
    "transform_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pd.DataFrame(transform_pipeline.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "#:# model\n",
    "\n",
    "params = {params}\n",
    "\n",
    "classifier = {classifier_class.__name__}(**params)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#:# hash\n",
    "#:# {md5}\n",
    "md5 = hashlib.md5(str(classifier).encode('utf-8')).hexdigest()\n",
    "print(f'md5: {{md5}}')\n",
    "\n",
    "#:# audit\n",
    "y_pred = classifier.predict(transform_pipeline.transform(X_test))\n",
    "y_pred_proba = classifier.predict_proba(transform_pipeline.transform(X_test))[:,1]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "print(f'acc: {{accuracy_score(y_test, y_pred)}}')\n",
    "print(f'auc: {{roc_auc_score(y_test, y_pred_proba)}}')\n",
    "print(f'precision: {{precision_score(y_test, y_pred)}}')\n",
    "print(f'recall: {{recall_score(y_test, y_pred)}}')\n",
    "print(f'specificity: {{tn/(tn+fp)}}')\n",
    "print(f'f1: {{f1_score(y_test, y_pred)}}')\n",
    "\n",
    "#:# session info\n",
    "\n",
    "# Dodaj wersjÄ™ pythona w session info\n",
    "\n",
    "sessionInfo = {{\n",
    "    \"python_version\": python_version(),\n",
    "    \"library_versions\":[str(d) for d in pkg_resources.working_set]\n",
    "}}\n",
    "with open('sessionInfo.txt', 'w') as f:\n",
    "    json.dump(sessionInfo, f, indent=4)\n",
    "    \"\"\"\n",
    "    with open(f'{repository_absolute_path}/models/{dataset_id}/{task_id}/{md5}/code.py', 'w') as fp:\n",
    "        fp.write(code_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:39.453941Z",
     "start_time": "2019-04-02T22:21:39.446971Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, ParameterGrid\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm.classes import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import pkg_resources\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:39.793638Z",
     "start_time": "2019-04-02T22:21:39.790185Z"
    }
   },
   "outputs": [],
   "source": [
    "added_by = \"Siemashko\"\n",
    "dataset_id = \"openml_boston\"\n",
    "task_type = \"classification\"\n",
    "task_target = \"binaryClass\"\n",
    "dataset_openml_id = 853\n",
    "repository_absolute_path = \"/home/siemashko/Desktop/2019L-WarsztatyBadawcze\"\n",
    "generate_task_json(dataset_id, task_type, task_target, added_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:40.125502Z",
     "start_time": "2019-04-02T22:21:40.107478Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(dataset_openml_id, task_target)\n",
    "transform_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pd.DataFrame(transform_pipeline.fit_transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set models to create and specify the param grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:40.537880Z",
     "start_time": "2019-04-02T22:21:40.528880Z"
    }
   },
   "outputs": [],
   "source": [
    "models_to_create = {}\n",
    "models_to_create[SVC] = list(ParameterGrid([{'kernel': ['linear'],\n",
    "                                        \"probability\": [True],\n",
    "                                        \"C\": [1,2,3,5,10]},\n",
    "                                       {'kernel': ['rbf', 'sigmoid'],\n",
    "                                        'gamma': [1, 3, 5, 7, 10],\n",
    "                                        \"probability\": [True]}]))\n",
    "\n",
    "models_to_create[RandomForestClassifier] = list(ParameterGrid([{\"n_estimators\":[25,75,150,300,600],\n",
    "                                                                \"max_depth\":[3,5,7]}]))\n",
    "\n",
    "models_to_create[AdaBoostClassifier] = list(ParameterGrid([{\"n_estimators\":[25,75,150,300,600],\n",
    "                                                            \"learning_rate\": [0.5,0.75,1.0]}]))\n",
    "\n",
    "models_to_create[LogisticRegression] = list(ParameterGrid([{\"solver\": ['liblinear', 'sag', 'saga'],\n",
    "                                                            \"C\": [0.2, 0.4, 0.6, 0.8, 1.0]}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's generate everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T22:21:52.813160Z",
     "start_time": "2019-04-02T22:21:41.322420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md5 hash: 43d227cc7efa0a4cee5561ca8fa67cd6\n",
      "md5 hash: 5d0ef2943274babaa8ffdc44806969fa\n",
      "md5 hash: b76f91e625461db4ff79add1a1f6b2fd\n",
      "md5 hash: 1b2ae3896802721475b2b96e5717707a\n",
      "md5 hash: 6652b5806fde3819cc18722add2b9de2\n",
      "md5 hash: de79316bb99fb627637bec6d2d8ebf9a\n",
      "md5 hash: 5450f634b38d0176cd0fee5c58d119ae\n",
      "md5 hash: fb5079f665ad626649b88a2f9184c9b1\n",
      "md5 hash: df94da09f57f342815273eff788904e3\n",
      "md5 hash: 6232a6d03c170d5991895983968835ac\n",
      "md5 hash: aad366f6d5961bc98783c2ad9fb3918d\n",
      "md5 hash: a1037b17a14bb76f44b4341d88d32d1c\n",
      "md5 hash: 0570deacf01bb82e54171b62cbf5e909\n",
      "md5 hash: 450a83cf002478d586f76a1a2e2acc9a\n",
      "md5 hash: fd39940d73b3520bc363cc9825c33449\n",
      "md5 hash: e352321c86c86dd2c42f72e19c802015\n",
      "md5 hash: 5475503c9e4b64dc0dcc4960399cf72c\n",
      "md5 hash: e763412d8e1070cf29ed7ed5f8d67a8e\n",
      "md5 hash: bf7d60a8ac3d7cac141c27c44bce5ddd\n",
      "md5 hash: 1fa5683f41d41a252c84a84d0ac110e2\n",
      "md5 hash: 15a5d9326e73c72861477f8b912aaa4a\n",
      "md5 hash: 8187bc79526114bd041f226851977941\n",
      "md5 hash: e315788413ea98a4d62051e59f55a3f7\n",
      "md5 hash: c021da80e62d7c2484a78d973f2b7434\n",
      "md5 hash: 8c6b1c9ffbc12e9aed6e9135b67cec99\n",
      "md5 hash: 0a19ea5de6f297dcd5d5ee21da160195\n",
      "md5 hash: 1720063a9b2a6894330753fe562cbc42\n",
      "md5 hash: c254ad755841ab6714725590c9b1f4b4\n",
      "md5 hash: 10ff5cfb4070b8cdc1e6b3392ed3a22b\n",
      "md5 hash: 343f2267c3fd97efdfb9f5616d978a0b\n",
      "md5 hash: 50e80aa093025b31cb5139767cfe4ede\n",
      "md5 hash: 7da2f9a50cb6040b2806d579b992c831\n",
      "md5 hash: d46676462c68cd80b52f93c3937041f3\n",
      "md5 hash: e595f5d5683f3e3692608020cd5bde18\n",
      "md5 hash: 5f496e444cfe2284de73b5c4dcb6d9ab\n",
      "md5 hash: 226fdb93dcc7f4bf0a3149387cec9c82\n",
      "md5 hash: 3e3663522a757679289b00b0c896c400\n",
      "md5 hash: b1141eaeb9eceeb7b2b26218a6da7dc7\n",
      "md5 hash: befe8b54c1ae99d80b5249719d280d30\n",
      "md5 hash: e0feb828e3da9bcad6df98cc099fec9d\n",
      "md5 hash: 04c1671140112465ff54c99bd2cc5c81\n",
      "md5 hash: 8b1760c08308a3e195be6359036bbfea\n",
      "md5 hash: 34d973a4c43713da9d9d3ed79ccb26b7\n",
      "md5 hash: dc2fb5ab89a23abd2a16b2a4316ee786\n",
      "md5 hash: 43a3621ec98c7550a6444091a2c4e971\n",
      "md5 hash: 09ced547af3b0bdfaeaff1e6bffeb31b\n",
      "md5 hash: 5fcc972afc8a88dfb56d74de6ebc4383\n",
      "md5 hash: e4340b5edd21086789b64d59bf6fe2d7\n",
      "md5 hash: 1ad9947a1f58f8427c7dc39c082e2105\n",
      "md5 hash: b5e154004802fe90d1408996313131a3\n",
      "md5 hash: 316326b05ffde4a9e0048dd1deeeaff4\n",
      "md5 hash: 9b6b3709d7b1adb241c987c95ede15c0\n",
      "md5 hash: 181bed94630731da599597452ebad663\n",
      "md5 hash: 9d5c5a077f19a6753d2d39c0f94135d6\n",
      "md5 hash: 8b4aedd7d78f7193c71d75501c5c1bc6\n",
      "md5 hash: 5675fd91f06b1105097dd77c85566e36\n",
      "md5 hash: a2380b83c1661086d689db8536086f4e\n",
      "md5 hash: c18ee48b9fa57d5f7a31c39b6cb039ce\n",
      "md5 hash: 9427b3c4a29162fd86a944be00946b51\n",
      "md5 hash: 757409d13b8bbf1939d4aab8971b3d6d\n"
     ]
    }
   ],
   "source": [
    "for classifier_class, param_grid in models_to_create.items():\n",
    "    for param_set in param_grid:\n",
    "        generate_model_audit_json_and_code_py_for_classifier(classifier_class, param_set, repository_absolute_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
