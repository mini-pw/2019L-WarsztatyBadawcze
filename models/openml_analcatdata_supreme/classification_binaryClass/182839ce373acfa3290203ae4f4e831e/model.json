[
  {
    "id": "182839ce373acfa3290203ae4f4e831e",
    "added_by": "MatiFilozof",
    "date": "08-06-2019",
    "library": "mlr",
    "model_name": "classif.ranger",
    "task_id": "classification_binaryClass",
    "dataset_id": "openml_analcatdata_supreme",
    "parameters": {
      "num.trees": 500,
      "mtry": null,
      "mtry.perc": null,
      "min.node.size": null,
      "replace": true,
      "sample.fraction": null,
      "split.select.weights": null,
      "always.split.variables": null,
      "respect.unordered.factors": "order",
      "importance": "none",
      "write.forest": true,
      "scale.permutation.importance": false,
      "num.threads": 1,
      "save.memory": false,
      "verbose": false,
      "seed": null,
      "splitrule": "gini",
      "num.random.splits": 1,
      "keep.inbag": false
    },
    "preprocessing": {
      "Actions_taken": {
        "name": "Actions_taken",
        "type": "numerical",
        "number_of_unique_values": 10,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 0,
        "num_mean": 0.1088,
        "num_3qu": 0,
        "num_maximum": 11
      },
      "Liberal": {
        "name": "Liberal",
        "type": "numerical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 1,
        "num_mean": 0.5197,
        "num_3qu": 1,
        "num_maximum": 1
      },
      "Unconstitutional": {
        "name": "Unconstitutional",
        "type": "numerical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 0,
        "num_mean": 0.0782,
        "num_3qu": 0,
        "num_maximum": 1
      },
      "Precedent_alteration": {
        "name": "Precedent_alteration",
        "type": "numerical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 0,
        "num_mean": 0.023,
        "num_3qu": 0,
        "num_maximum": 1
      },
      "Unanimous": {
        "name": "Unanimous",
        "type": "numerical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 0,
        "num_mean": 0.3376,
        "num_3qu": 1,
        "num_maximum": 1
      },
      "Year_of_decision": {
        "name": "Year_of_decision",
        "type": "numerical",
        "number_of_unique_values": 36,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 1953,
        "num_1qu": 1964,
        "num_median": 1973,
        "num_mean": 1972.3485,
        "num_3qu": 1981,
        "num_maximum": 1988
      },
      "Lower_court_disagreement": {
        "name": "Lower_court_disagreement",
        "type": "numerical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": null,
        "num_minimum": 0,
        "num_1qu": 0,
        "num_median": 0,
        "num_mean": 0.2256,
        "num_3qu": 0,
        "num_maximum": 1
      },
      "binaryClass": {
        "name": "binaryClass",
        "type": "categorical",
        "number_of_unique_values": 2,
        "number_of_missing_values": 0,
        "cat_frequencies": {
          "P": 971,
          "N": 3081
        },
        "num_minimum": null,
        "num_1qu": null,
        "num_median": null,
        "num_mean": null,
        "num_3qu": null,
        "num_maximum": null
      }
    }
  }
]
